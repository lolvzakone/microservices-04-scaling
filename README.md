
# Домашнее задание к занятию «Микросервисы: масштабирование»

Вы работаете в крупной компании, которая строит систему на основе микросервисной архитектуры.
Вам как DevOps-специалисту необходимо выдвинуть предложение по организации инфраструктуры для разработки и эксплуатации.

## Задача 1: Кластеризация

Предложите решение для обеспечения развёртывания, запуска и управления приложениями.
Решение может состоять из одного или нескольких программных продуктов и должно описывать способы и принципы их взаимодействия.

Решение должно соответствовать следующим требованиям:
- поддержка контейнеров;
- обеспечивать обнаружение сервисов и маршрутизацию запросов;
- обеспечивать возможность горизонтального масштабирования;
- обеспечивать возможность автоматического масштабирования;
- обеспечивать явное разделение ресурсов, доступных извне и внутри системы;
- обеспечивать возможность конфигурировать приложения с помощью переменных среды, в том числе с возможностью безопасного хранения чувствительных данных таких как пароли, ключи доступа, ключи шифрования и т. п.

Обоснуйте свой выбор.

## Задача 2: Распределённый кеш * (необязательная)

Разработчикам вашей компании понадобился распределённый кеш для организации хранения временной информации по сессиям пользователей.
Вам необходимо построить Redis Cluster, состоящий из трёх шард с тремя репликами.

### Схема:

![11-04-01](https://user-images.githubusercontent.com/1122523/114282923-9b16f900-9a4f-11eb-80aa-61ed09725760.png)

---

### Как оформить ДЗ?

Выполненное домашнее задание пришлите ссылкой на .md-файл в вашем репозитории.

---

# Инфраструктурное решение на базе Kubernetes для микросервисов

Для построения надёжной, масштабируемой и безопасной инфраструктуры для разработки и эксплуатации микросервисов предлагается использовать **Kubernetes** в качестве платформы оркестрации. Это решение, дополненное набором стандартных для индустрии инструментов, позволяет эффективно решать все ключевые задачи.

## Архитектура и основные компоненты

В основе решения лежит кластер Kubernetes, который управляет жизненным циклом контейнеризованных приложений.

| Компонент | Роль в архитектуре |
| :--- | :--- |
| **Kubernetes** | **Оркестрация:** Развертывание, управление и масштабирование контейнеров (Docker, containerd). |
| **Ingress Controller** (например, NGINX, Traefik) | **Точка входа:** Управляет входящим трафиком, выполняет TLS-терминацию и маршрутизирует запросы к нужным сервисам. |
| **Horizontal Pod Autoscaler (HPA)** | **Автомасштабирование приложений:** Автоматически изменяет количество реплик (подов) сервиса в зависимости от текущей нагрузки (CPU, RAM). |
| **Cluster Autoscaler** | **Автомасштабирование кластера:** Добавляет или удаляет рабочие узлы (виртуальные машины) в кластер, обеспечивая наличие достаточных вычислительных ресурсов. |
| **Namespaces & Network Policies** | **Изоляция и безопасность:** Логически разделяет ресурсы (например, по средам `dev`/`stage`/`prod`) и контролирует сетевое взаимодействие между сервисами. |
| **ConfigMaps & Secrets** | **Управление конфигурацией:** Безопасно хранит и предоставляет приложениям конфигурационные данные, ключи API и пароли. |

## Принципы взаимодействия компонентов

1.  **Развертывание:** Приложения упаковываются в **Docker-контейнеры** и описываются в виде декларативных манифестов Kubernetes (например, `Deployment` для stateless-сервисов или `StatefulSet` для stateful).

2.  **Маршрутизация и обнаружение сервисов:**
    *   Внешний трафик поступает на **Ingress Controller**, который, согласно правилам (`Ingress`), направляет его на соответствующий **Kubernetes Service**.
    *   **Service** предоставляет стабильный сетевой адрес и DNS-имя для группы подов, обеспечивая прозрачное обнаружение и взаимодействие сервисов внутри кластера.

3.  **Масштабирование:**
    *   При росте нагрузки на сервис **HPA** обнаруживает это по метрикам и автоматически увеличивает количество его подов.
    *   Если в кластере не хватает ресурсов для новых подов, **Cluster Autoscaler** заказывает у облачного провайдера новые виртуальные машины и добавляет их в кластер. При снижении нагрузки лишние узлы так же автоматически удаляются для экономии средств.

4.  **Изоляция и безопасность:**
    *   Ресурсы разных команд или сред (например, `testing` и `production`) изолируются друг от друга с помощью **Namespaces**.
    *   **Network Policies** действуют как внутренний файрвол, разрешая или запрещая сетевое взаимодействие между подами. Например, можно разрешить бэкенду обращаться к базе данных, но запретить это делать фронтенду напрямую.

5.  **Управление конфигурацией:**
    *   Некритичные параметры (например, URL внешних сервисов) хранятся в **ConfigMaps**.
    *   Чувствительные данные (пароли, токены) хранятся в **Secrets**. Приложения получают доступ к этим данным через переменные окружения или смонтированные в файловую систему тома.

## Обоснование выбора

*   **Стандарт индустрии:** **Kubernetes** является де-факто стандартом для оркестрации контейнеров, что гарантирует широкую поддержку, огромное сообщество и богатую экосистему готовых инструментов.
*   **Эластичность и эффективность:** Связка **HPA** и **Cluster Autoscaler** позволяет инфраструктуре автоматически адаптироваться к любой нагрузке, оптимизируя как производительность, так и затраты на ресурсы.
*   **Встроенная безопасность:** Инструменты **Namespaces** и **Network Policies** предоставляют мощные нативные механизмы для сегментации и защиты внутренней сети кластера.
*   **Декларативное управление конфигурацией:** **ConfigMaps** и **Secrets** являются нативными ресурсами Kubernetes, что избавляет от необходимости внедрять и поддерживать отдельные сложные системы для управления конфигурациями и секретами, по крайней мере, на начальном этапе.
